{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e44523",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "\n",
    "Answer: In cae of simple Linear Regression we ahve one inpedendent variable and one dependent variable. Main aim of simple linear regression is to find the line(best fit line) where summation of errors should be minimum.\n",
    "\n",
    "Example: Weight vs height\n",
    "\n",
    "In case of Multiple Linear Regression, we have more than one independent variables. Example predicting house price with independent variables as Location, No of Rooms, House Size etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc029b",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "\n",
    "Linearity---> to check this we can use scatter plots\n",
    "Normality--> Residuals must be normally distributed. To check this We plot Q-Q plot(Points should be in straight line) and Histogram\n",
    "No Multi Collinearity---> VIF(Variance inflation factor). calculate VIF for each independent variable. If VIF> 10-- It suggest high multi collinearity\n",
    "Correlation matrix--> It can also be used to check Multi collinearity\n",
    "Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a0e02",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "Trying to explain by an example\n",
    "\n",
    "y = a bx1+ cx2\n",
    "\n",
    "price = 50000 + 0.67(Total no of rooms) + .82(Locality)\n",
    "\n",
    "If we change locality by one unit, there is 0.82 unit change in price\n",
    "Intercept- Baseline value of dependent variable, where all independent variables are 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658a5a7",
   "metadata": {},
   "source": [
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "It is an optimization algorithm which is used to minimize the cost function so that predicted values should be close enough to the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789847c",
   "metadata": {},
   "source": [
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Multiple linear regression is an extension of simple linear regression that models the relationship between two or more independent variables and a dependent variable. The model is represented by the equation:\n",
    "\n",
    "\\[ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n + \\epsilon \\]\n",
    "\n",
    "where:\n",
    "- \\( y \\) is the dependent variable.\n",
    "- \\( \\beta_0 \\) is the intercept.\n",
    "- \\( \\beta_1, \\beta_2, \\ldots, \\beta_n \\) are the coefficients for each independent variable \\( x_1, x_2, \\ldots, x_n \\).\n",
    "- \\( \\epsilon \\) is the error term.\n",
    "\n",
    "In contrast, simple linear regression involves only one independent variable and is represented by the equation:\n",
    "\n",
    "\\[ y = \\beta_0 + \\beta_1 x + \\epsilon \\]\n",
    "\n",
    "Key differences:\n",
    "- **Number of Independent Variables:** Simple linear regression uses one independent variable, while multiple linear regression uses two or more.\n",
    "- **Complexity:** Multiple linear regression can capture more complex relationships due to the inclusion of multiple predictors.\n",
    "- **Interpretation:** In multiple linear regression, each coefficient represents the change in the dependent variable for a one-unit change in the corresponding independent variable, holding all other variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cc918",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "\n",
    "Multi-collinearity: When one or more are highly correlated \n",
    "\n",
    "#### Detection \n",
    "\n",
    "1. Correlation Matrix \n",
    "2. VIF\n",
    "\n",
    "#### Addressing\n",
    "1. Remove highly correlated independent variables\n",
    "2. Combine two or more correlated variables\n",
    "3. PCA\n",
    "4. Ridge Regression, Lasso Regression--> Adding penality terms to reduce or shrink the value of coefficients. In case of lasso regression--> few cofficients can also turn to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054a4c5",
   "metadata": {},
   "source": [
    "### Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "Polynomial regression is a type of regression analysis that models the relationship between the independent variable(s) and the dependent variable as an nth-degree polynomial. The model is represented by the equation:\n",
    "\n",
    "\\[ y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\ldots + \\beta_n x^n + \\epsilon \\]\n",
    "\n",
    "where:\n",
    "- \\( y \\) is the dependent variable.\n",
    "- \\( x \\) is the independent variable.\n",
    "- \\( \\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_n \\) are the coefficients.\n",
    "- \\( \\epsilon \\) is the error term.\n",
    "\n",
    "Key differences from linear regression:\n",
    "1. **Form of the Relationship:** Linear regression models a linear relationship between the independent and dependent variables (i.e., a straight line), whereas polynomial regression models a nonlinear relationship, which can be represented by a curve.\n",
    "2. **Complexity:** Polynomial regression can capture more complex, curved relationships by incorporating higher-degree terms of the independent variable.\n",
    "3. **Flexibility:** By increasing the degree of the polynomial (the value of \\( n \\)), the model can fit more complex patterns in the data, although this can also lead to overfitting if \\( n \\) is too high.\n",
    "\n",
    "In summary, while linear regression is suitable for linear relationships, polynomial regression extends this to capture nonlinear relationships using polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9f200",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "### Advantages of Polynomial Regression:\n",
    "\n",
    "1. **Flexibility:** Polynomial regression can model complex, nonlinear relationships between the independent and dependent variables, providing a better fit for datasets with curved patterns.\n",
    "2. **Improved Fit:** It can reduce the error by fitting the training data more accurately when the relationship between variables is inherently nonlinear.\n",
    "\n",
    "### Disadvantages of Polynomial Regression:\n",
    "\n",
    "1. **Overfitting:** Higher-degree polynomials can lead to overfitting, where the model captures noise in the training data rather than the underlying pattern, resulting in poor generalization to new data.\n",
    "2. **Complexity:** As the degree of the polynomial increases, the model becomes more complex and computationally intensive, making it harder to interpret and more prone to instability.\n",
    "3. **Multicollinearity:** Polynomial terms can be highly correlated, leading to multicollinearity, which can affect the reliability of the coefficient estimates.\n",
    "\n",
    "### Situations to Prefer Polynomial Regression:\n",
    "\n",
    "1. **Nonlinear Relationships:** When the relationship between the independent and dependent variables is known to be nonlinear and cannot be well approximated by a straight line.\n",
    "2. **Data Patterns:** When exploratory data analysis indicates curved trends or patterns in the data that a linear model cannot capture.\n",
    "3. **Domain Knowledge:** When prior knowledge or theory suggests a polynomial relationship, such as in certain physical phenomena (e.g., the motion of objects under the influence of gravity).\n",
    "\n",
    "In summary, polynomial regression is advantageous for capturing nonlinear relationships but comes with the risk of overfitting and increased complexity. It is preferred when the data exhibits curved patterns that a linear model cannot fit adequately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0e2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
