{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07a2238",
   "metadata": {},
   "source": [
    "## Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e937f5",
   "metadata": {},
   "source": [
    "It is a process of combining multiple models to improve accuracy and performance. In the random forest classifier, we combine multiple decision trees, apply row and feature sampling, and then do majority voting to predict the output; similarly, in custom ensemble models, we can use multiple models; it could be Naïve Bayes, decision trees, Logistic Regression, or SVC. Then we can combine these models and do majority voting to predict the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de1cc4",
   "metadata": {},
   "source": [
    "## Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15501c52",
   "metadata": {},
   "source": [
    "•\tTo reduce overfitting.\n",
    "•\tImprove Performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbac4c2",
   "metadata": {},
   "source": [
    "## Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af20bb0",
   "metadata": {},
   "source": [
    "Bagging, short for Bootstrap Aggregating, is an ensemble technique in machine learning that aims to improve the accuracy of models by combining the predictions of multiple base learners trained on different subsets of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aeddda",
   "metadata": {},
   "source": [
    "## Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7365e9",
   "metadata": {},
   "source": [
    "Boosting is another ensemble technique in machine learning that combines multiple weak learners sequentially to create a strong learner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895e1003",
   "metadata": {},
   "source": [
    "## Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82821f43",
   "metadata": {},
   "source": [
    "•\tReduced Overfitting.\n",
    "•\tImproved performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e34f23",
   "metadata": {},
   "source": [
    "## Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb66346",
   "metadata": {},
   "source": [
    "This is based on the use case and data, but they tend to be better than individual models, as chances of overfitting are comparatively minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ec696",
   "metadata": {},
   "source": [
    "## Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f819ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
