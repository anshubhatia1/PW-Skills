{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c83a1e0",
   "metadata": {},
   "source": [
    "### Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example.\n",
    "\n",
    "**Eigenvalues** and **eigenvectors** are fundamental concepts in linear algebra associated with square matrices. Given a square matrix \\( A \\), an eigenvector \\( v \\) is a non-zero vector such that when \\( A \\) is multiplied by \\( v \\), the result is a scalar multiple of \\( v \\). This scalar is called the eigenvalue \\( \\lambda \\). Mathematically, this is represented as:\n",
    "\n",
    "\\[ A v = \\lambda v \\]\n",
    "\n",
    "Where:\n",
    "- \\( A \\) is the square matrix.\n",
    "- \\( v \\) is the eigenvector.\n",
    "- \\( \\lambda \\) is the eigenvalue.\n",
    "\n",
    "**Eigen-Decomposition** is the process of decomposing a matrix into its eigenvalues and eigenvectors. For a square matrix \\( A \\), if it can be decomposed, it is represented as:\n",
    "\n",
    "\\[ A = V \\Lambda V^{-1} \\]\n",
    "\n",
    "Where:\n",
    "- \\( V \\) is a matrix whose columns are the eigenvectors of \\( A \\).\n",
    "- \\( \\Lambda \\) is a diagonal matrix whose diagonal elements are the eigenvalues of \\( A \\).\n",
    "- \\( V^{-1} \\) is the inverse of the matrix \\( V \\).\n",
    "\n",
    "**Example**:\n",
    "Consider the matrix \\( A \\):\n",
    "\n",
    "\\[ A = \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} \\]\n",
    "\n",
    "To find the eigenvalues, we solve the characteristic equation \\( \\det(A - \\lambda I) = 0 \\):\n",
    "\n",
    "\\[ \\det \\begin{pmatrix} 4-\\lambda & 1 \\\\ 2 & 3-\\lambda \\end{pmatrix} = (4-\\lambda)(3-\\lambda) - 2 = \\lambda^2 - 7\\lambda + 10 = 0 \\]\n",
    "\n",
    "Solving \\( \\lambda^2 - 7\\lambda + 10 = 0 \\), we get the eigenvalues \\( \\lambda_1 = 5 \\) and \\( \\lambda_2 = 2 \\).\n",
    "\n",
    "For each eigenvalue, we find the corresponding eigenvector:\n",
    "\n",
    "For \\( \\lambda_1 = 5 \\):\n",
    "\n",
    "\\[ (A - 5I) v = 0 \\]\n",
    "\n",
    "\\[ \\begin{pmatrix} -1 & 1 \\\\ 2 & -2 \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\]\n",
    "\n",
    "Solving, we get \\( v_1 = v_2 \\). Thus, one eigenvector is \\( v_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\).\n",
    "\n",
    "For \\( \\lambda_2 = 2 \\):\n",
    "\n",
    "\\[ (A - 2I) v = 0 \\]\n",
    "\n",
    "\\[ \\begin{pmatrix} 2 & 1 \\\\ 2 & 1 \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\]\n",
    "\n",
    "Solving, we get \\( v_1 = -v_2 \\). Thus, another eigenvector is \\( v_2 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\).\n",
    "\n",
    "### Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "\n",
    "**Eigen decomposition** is the process of decomposing a square matrix \\( A \\) into its eigenvalues and eigenvectors. If \\( A \\) is a square matrix, and if it is diagonalizable, it can be written as:\n",
    "\n",
    "\\[ A = V \\Lambda V^{-1} \\]\n",
    "\n",
    "Where:\n",
    "- \\( V \\) is a matrix whose columns are the eigenvectors of \\( A \\).\n",
    "- \\( \\Lambda \\) is a diagonal matrix whose diagonal elements are the eigenvalues of \\( A \\).\n",
    "- \\( V^{-1} \\) is the inverse of \\( V \\).\n",
    "\n",
    "**Significance in Linear Algebra**:\n",
    "- **Simplification**: Eigen decomposition simplifies matrix operations, especially raising matrices to powers.\n",
    "- **Understanding Systems**: Helps in understanding the behavior of linear transformations.\n",
    "- **Diagonalization**: Used for diagonalizing matrices, which is crucial in many applications like solving differential equations and analyzing stability.\n",
    "- **Principal Component Analysis (PCA)**: Essential in PCA for reducing the dimensionality of data while preserving variance.\n",
    "\n",
    "### Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.\n",
    "\n",
    "A square matrix \\( A \\) is diagonalizable if and only if there are enough linearly independent eigenvectors to form a basis of the vector space. Specifically, \\( A \\) is diagonalizable if:\n",
    "\n",
    "1. \\( A \\) has \\( n \\) linearly independent eigenvectors, where \\( n \\) is the size of the matrix.\n",
    "2. The geometric multiplicity of each eigenvalue (the number of linearly independent eigenvectors associated with it) equals its algebraic multiplicity (the number of times the eigenvalue appears as a root of the characteristic polynomial).\n",
    "\n",
    "**Proof**:\n",
    "Let \\( A \\) be an \\( n \\times n \\) matrix with \\( n \\) linearly independent eigenvectors \\( v_1, v_2, \\ldots, v_n \\). Construct a matrix \\( V \\) with these eigenvectors as columns:\n",
    "\n",
    "\\[ V = \\begin{pmatrix} v_1 & v_2 & \\cdots & v_n \\end{pmatrix} \\]\n",
    "\n",
    "Then:\n",
    "\n",
    "\\[ AV = A \\begin{pmatrix} v_1 & v_2 & \\cdots & v_n \\end{pmatrix} = \\begin{pmatrix} Av_1 & Av_2 & \\cdots & Av_n \\end{pmatrix} = \\begin{pmatrix} \\lambda_1 v_1 & \\lambda_2 v_2 & \\cdots & \\lambda_n v_n \\end{pmatrix} \\]\n",
    "\n",
    "\\[ AV = V \\Lambda \\]\n",
    "\n",
    "Where \\( \\Lambda \\) is a diagonal matrix with eigenvalues \\( \\lambda_1, \\lambda_2, \\ldots, \\lambda_n \\) on the diagonal. Thus, \\( A = V \\Lambda V^{-1} \\), proving that \\( A \\) is diagonalizable.\n",
    "\n",
    "### Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.\n",
    "\n",
    "The **spectral theorem** states that any symmetric (or more generally, normal) matrix can be diagonalized by an orthogonal (or unitary) matrix. This means that for a symmetric matrix \\( A \\), there exists an orthogonal matrix \\( Q \\) and a diagonal matrix \\( \\Lambda \\) such that:\n",
    "\n",
    "\\[ A = Q \\Lambda Q^T \\]\n",
    "\n",
    "**Significance**:\n",
    "- It guarantees that all eigenvalues of a symmetric matrix are real.\n",
    "- It ensures that the eigenvectors of a symmetric matrix are orthogonal.\n",
    "- Simplifies many computations and theoretical analyses, especially in physics and engineering.\n",
    "\n",
    "**Example**:\n",
    "Consider the symmetric matrix \\( A \\):\n",
    "\n",
    "\\[ A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix} \\]\n",
    "\n",
    "We can find the eigenvalues and eigenvectors as described in Q1. The eigenvalues are \\( \\lambda_1 = 5 \\) and \\( \\lambda_2 = 2 \\), with corresponding orthogonal eigenvectors \\( v_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\) and \\( v_2 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\).\n",
    "\n",
    "The matrix \\( Q \\) formed by normalizing these eigenvectors is:\n",
    "\n",
    "\\[ Q = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix} \\]\n",
    "\n",
    "And the diagonal matrix \\( \\Lambda \\) is:\n",
    "\n",
    "\\[ \\Lambda = \\begin{pmatrix} 5 & 0 \\\\ 0 & 2 \\end{pmatrix} \\]\n",
    "\n",
    "Thus, \\( A = Q \\Lambda Q^T \\).\n",
    "\n",
    "### Q5. How do you find the eigenvalues of a matrix and what do they represent?\n",
    "\n",
    "To find the eigenvalues of a matrix \\( A \\), follow these steps:\n",
    "\n",
    "1. **Form the Characteristic Equation**: Subtract \\( \\lambda \\) times the identity matrix \\( I \\) from \\( A \\) and set the determinant to zero:\n",
    "   \\[\n",
    "   \\det(A - \\lambda I) = 0\n",
    "   \\]\n",
    "2. **Solve the Polynomial Equation**: The characteristic equation is a polynomial in \\( \\lambda \\). Solve this polynomial equation to find the eigenvalues.\n",
    "\n",
    "**Representation**:\n",
    "- **Eigenvalues** represent the factors by which the eigenvectors are scaled during the transformation defined by the matrix \\( A \\).\n",
    "- They indicate the magnitude of stretching or compressing along the direction of their corresponding eigenvectors.\n",
    "\n",
    "### Q6. What are eigenvectors and how are they related to eigenvalues?\n",
    "\n",
    "**Eigenvectors** are non-zero vectors that, when transformed by a matrix \\( A \\), result in a scalar multiple of themselves. This scalar multiple is the corresponding **eigenvalue** \\( \\lambda \\).\n",
    "\n",
    "The relationship is given by:\n",
    "\n",
    "\\[ A v = \\lambda v \\]\n",
    "\n",
    "Where:\n",
    "- \\( A \\) is the square matrix.\n",
    "- \\( v \\) is the eigenvector.\n",
    "- \\( \\lambda \\) is the eigenvalue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bbd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
